{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 58907.5977 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch   2 - Loss: 51285.7578 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   3 - Loss: 41996.0508 Validation Accuracy: 0.109375\n",
      "Epoch  1, Batch   4 - Loss: 34928.1094 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch   5 - Loss: 32830.6758 Validation Accuracy: 0.125000\n",
      "Epoch  1, Batch   6 - Loss: 28736.9414 Validation Accuracy: 0.140625\n",
      "Epoch  1, Batch   7 - Loss: 26849.3887 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch   8 - Loss: 27948.3633 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   9 - Loss: 26422.9902 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch  10 - Loss: 24309.6250 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch  11 - Loss: 21709.2168 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  12 - Loss: 21392.4609 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  13 - Loss: 20311.3848 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  14 - Loss: 17175.9297 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  15 - Loss: 20147.8320 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  16 - Loss: 20136.5078 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  17 - Loss: 17890.0469 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  18 - Loss: 19262.6250 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  19 - Loss: 16007.2715 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  20 - Loss: 19099.3008 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  21 - Loss: 18374.5156 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  22 - Loss: 21456.1250 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  23 - Loss: 17379.3086 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  24 - Loss: 14424.5107 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  25 - Loss: 14324.6387 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  26 - Loss: 15687.9326 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  27 - Loss: 16065.8984 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  28 - Loss: 13811.2021 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  29 - Loss: 15983.1406 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  30 - Loss: 14310.4053 Validation Accuracy: 0.332031\n",
      "Epoch  1, Batch  31 - Loss: 12820.8984 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  32 - Loss: 12189.7422 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  33 - Loss: 11903.0859 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  34 - Loss:  9253.4727 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  35 - Loss: 12259.8672 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  36 - Loss: 12668.6680 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  37 - Loss:  9311.6992 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  38 - Loss:  9963.1016 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  39 - Loss: 10060.1309 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  40 - Loss:  8850.0762 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  41 - Loss: 10784.2227 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  42 - Loss: 10096.6914 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  43 - Loss:  7950.7969 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  44 - Loss:  9769.9102 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  45 - Loss: 10404.3145 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  46 - Loss:  9280.4961 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  47 - Loss:  9154.7012 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  48 - Loss:  8101.9658 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  49 - Loss:  9060.1465 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  50 - Loss:  7433.0049 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  51 - Loss:  8852.2207 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  52 - Loss:  9434.9658 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  53 - Loss:  8918.5811 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  54 - Loss:  7834.6895 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  55 - Loss: 10922.5547 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  56 - Loss:  5795.7300 Validation Accuracy: 0.417969\n",
      "Epoch  1, Batch  57 - Loss:  9670.6289 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  58 - Loss:  8452.5264 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  59 - Loss:  7661.1992 Validation Accuracy: 0.421875\n",
      "Epoch  1, Batch  60 - Loss:  9508.1230 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  61 - Loss:  7309.9556 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  62 - Loss:  7421.7920 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  63 - Loss:  8657.4629 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  64 - Loss:  8527.6768 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  65 - Loss:  8060.2920 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  66 - Loss:  6755.5674 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  67 - Loss:  7906.9312 Validation Accuracy: 0.453125\n",
      "Epoch  1, Batch  68 - Loss:  7695.6987 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  69 - Loss:  6447.6738 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  70 - Loss:  7134.7158 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  71 - Loss:  8938.7285 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  72 - Loss:  7961.7788 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  73 - Loss:  6767.5947 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  74 - Loss:  7835.8184 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  75 - Loss:  6342.5283 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  76 - Loss:  8851.7500 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  77 - Loss: 10086.7988 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  78 - Loss:  5857.3662 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  79 - Loss:  5347.6597 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  80 - Loss:  6514.6377 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  81 - Loss:  5583.0674 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  82 - Loss:  6885.8428 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  83 - Loss:  6875.1909 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  84 - Loss:  7127.7432 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  85 - Loss:  8628.1865 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  86 - Loss:  6317.0420 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  87 - Loss:  6861.6514 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  88 - Loss:  5623.4658 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  89 - Loss:  5479.7695 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  90 - Loss:  5878.6260 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  91 - Loss:  5239.3403 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  92 - Loss:  5283.7178 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  93 - Loss:  6414.9370 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  94 - Loss:  5888.8911 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  95 - Loss:  6035.2021 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch  96 - Loss:  6689.5830 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch  97 - Loss:  6326.8018 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch  98 - Loss:  5808.4932 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch  99 - Loss:  8124.0859 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 100 - Loss:  6200.5967 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 101 - Loss:  5118.7285 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 102 - Loss:  4350.9199 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 103 - Loss:  4228.4482 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 104 - Loss:  4477.5894 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 105 - Loss:  4785.7495 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 106 - Loss:  4053.7754 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 107 - Loss:  4685.5171 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 108 - Loss:  4899.7051 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 109 - Loss:  4058.7864 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 110 - Loss:  5894.6348 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 111 - Loss:  6152.2827 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 112 - Loss:  4915.3594 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 113 - Loss:  5853.7476 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 114 - Loss:  6285.3384 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 115 - Loss:  4289.3154 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 116 - Loss:  4914.0283 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 117 - Loss:  5603.2275 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 118 - Loss:  5736.7676 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 119 - Loss:  5548.1489 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 120 - Loss:  4713.3105 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 121 - Loss:  4041.8611 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 122 - Loss:  4750.9932 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 123 - Loss:  3619.3208 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 124 - Loss:  4804.4580 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 125 - Loss:  5818.2705 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 126 - Loss:  4312.4639 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 127 - Loss:  3121.3071 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 128 - Loss:  5252.8262 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 129 - Loss:  4869.2427 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 130 - Loss:  3412.7998 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 131 - Loss:  3317.2197 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 132 - Loss:  2735.2173 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 133 - Loss:  2952.4375 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 134 - Loss:  5434.5723 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 135 - Loss:  5219.4756 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 136 - Loss:  3923.5105 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 137 - Loss:  4865.6616 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 138 - Loss:  5560.4150 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 139 - Loss:  4713.6943 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 140 - Loss:  4590.3291 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 141 - Loss:  4238.8965 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 142 - Loss:  4558.7393 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 143 - Loss:  3400.0518 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 144 - Loss:  3328.7146 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 145 - Loss:  3648.4226 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 146 - Loss:  4502.4473 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 147 - Loss:  3554.6440 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 148 - Loss:  2922.0791 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 149 - Loss:  3521.0972 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 150 - Loss:  3103.7329 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 151 - Loss:  4644.0757 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 152 - Loss:  3119.7441 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 153 - Loss:  3986.6851 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 154 - Loss:  4923.0981 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 155 - Loss:  4082.9878 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 156 - Loss:  4062.5498 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 157 - Loss:  3341.2007 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 158 - Loss:  3010.4165 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 159 - Loss:  3786.7019 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 160 - Loss:  3202.4607 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 161 - Loss:  3261.1772 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 162 - Loss:  3376.9570 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 163 - Loss:  3536.6033 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 164 - Loss:  4222.7744 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 165 - Loss:  2922.3374 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 166 - Loss:  2778.9111 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 167 - Loss:  3093.4922 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 168 - Loss:  3038.9170 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 169 - Loss:  2900.2427 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 170 - Loss:  3975.2280 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 171 - Loss:  3020.9023 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 172 - Loss:  3274.4299 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 173 - Loss:  4127.2441 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 174 - Loss:  4594.8721 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 175 - Loss:  3164.2739 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 176 - Loss:  3344.4390 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 177 - Loss:  2795.1633 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 178 - Loss:  3123.8958 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 179 - Loss:  2333.7004 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 180 - Loss:  1899.3767 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 181 - Loss:  2334.9102 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 182 - Loss:  3057.5171 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 183 - Loss:  2893.5659 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 184 - Loss:  3434.8657 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 185 - Loss:  3407.2568 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 186 - Loss:  3540.5930 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 187 - Loss:  3254.5625 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 188 - Loss:  3428.8440 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 189 - Loss:  3220.8130 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 190 - Loss:  2948.6738 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 191 - Loss:  3525.3562 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 192 - Loss:  2662.4453 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 193 - Loss:  2574.5469 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 194 - Loss:  3697.8906 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 195 - Loss:  3552.8428 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 196 - Loss:  3312.0464 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 197 - Loss:  3446.8501 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 198 - Loss:  3433.9783 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 199 - Loss:  3062.2151 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 200 - Loss:  3736.7744 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 201 - Loss:  3605.8376 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 202 - Loss:  2704.4373 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 203 - Loss:  2646.9731 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 204 - Loss:  3201.8325 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 205 - Loss:  2913.2405 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 206 - Loss:  4001.3269 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 207 - Loss:  3832.4722 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 208 - Loss:  2577.4268 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 209 - Loss:  3359.1318 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 210 - Loss:  2203.5181 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 211 - Loss:  3064.1201 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 212 - Loss:  3642.8186 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 213 - Loss:  4479.6348 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 214 - Loss:  4018.7188 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 215 - Loss:  3957.7122 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 216 - Loss:  2456.8203 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 217 - Loss:  2496.8369 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 218 - Loss:  2228.8708 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 219 - Loss:  2355.3003 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 220 - Loss:  4072.1428 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 221 - Loss:  3099.8213 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 222 - Loss:  2713.0928 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 223 - Loss:  3086.0796 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 224 - Loss:  2214.7935 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 225 - Loss:  1900.9948 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 226 - Loss:  1817.3157 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 227 - Loss:  2824.5864 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 228 - Loss:  2563.2935 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 229 - Loss:  2121.0295 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 230 - Loss:  2698.5305 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 231 - Loss:  2898.2942 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 232 - Loss:  2662.0212 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 233 - Loss:  2893.7429 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 234 - Loss:  3454.8369 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 235 - Loss:  1735.9022 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 236 - Loss:  2530.5830 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 237 - Loss:  2369.0493 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 238 - Loss:  2000.9475 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 239 - Loss:  2401.4939 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 240 - Loss:  2588.9631 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 241 - Loss:  2258.3562 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 242 - Loss:  2663.6699 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 243 - Loss:  2467.9922 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 244 - Loss:  2551.7192 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 245 - Loss:  2490.5674 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 246 - Loss:  2811.7532 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 247 - Loss:  2053.7461 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 248 - Loss:  2420.0129 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 249 - Loss:  2546.7295 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 250 - Loss:  1964.9000 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 251 - Loss:  2725.4553 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 252 - Loss:  2084.0161 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 253 - Loss:  3508.9580 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 254 - Loss:  3375.7634 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 255 - Loss:  3530.3171 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 256 - Loss:  2640.9258 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 257 - Loss:  2624.5300 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 258 - Loss:  2166.5071 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 259 - Loss:  2134.5352 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 260 - Loss:  2307.9951 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 261 - Loss:  2605.0867 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 262 - Loss:  2249.3350 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 263 - Loss:  2739.0952 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 264 - Loss:  1957.3059 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 265 - Loss:  2995.5552 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 266 - Loss:  1430.1841 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 267 - Loss:  1623.4988 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 268 - Loss:  1675.4971 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 269 - Loss:  3167.1152 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 270 - Loss:  3029.6355 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 271 - Loss:  2485.0098 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 272 - Loss:  2722.1641 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 273 - Loss:  2804.4849 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 274 - Loss:  2407.2778 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 275 - Loss:  2062.5488 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 276 - Loss:  1981.6261 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 277 - Loss:  1509.6046 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 278 - Loss:  2828.2014 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 279 - Loss:  2768.6226 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 280 - Loss:  1844.8966 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 281 - Loss:  1702.6705 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 282 - Loss:  2634.3994 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 283 - Loss:  2511.6799 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 284 - Loss:  2999.7317 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 285 - Loss:  3448.4802 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 286 - Loss:  3034.5801 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 287 - Loss:  1969.3542 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 288 - Loss:  2242.0181 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 289 - Loss:  2668.3853 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 290 - Loss:  2245.1567 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 291 - Loss:  2883.0962 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 292 - Loss:  3119.5317 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 293 - Loss:  2574.3728 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 294 - Loss:  2078.2837 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 295 - Loss:  2614.8374 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 296 - Loss:  2700.4609 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 297 - Loss:  2573.0210 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 298 - Loss:  2332.7166 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 299 - Loss:  1939.9366 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 300 - Loss:  1268.5977 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 301 - Loss:  1800.8934 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 302 - Loss:  1695.3206 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 303 - Loss:  2670.9451 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 304 - Loss:  1946.2383 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 305 - Loss:  2066.9478 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 306 - Loss:  2998.2168 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 307 - Loss:  2920.7632 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 308 - Loss:  2320.2344 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 309 - Loss:  1987.2981 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 310 - Loss:  1798.3750 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 311 - Loss:  1708.0623 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 312 - Loss:  2153.0894 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 313 - Loss:  1754.6621 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 314 - Loss:  1791.1577 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 315 - Loss:  1124.8560 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 316 - Loss:  2089.2119 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 317 - Loss:  1837.4021 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 318 - Loss:  1785.1436 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 319 - Loss:  2068.2310 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 320 - Loss:  1808.4711 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 321 - Loss:  2072.0259 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 322 - Loss:  1529.8213 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 323 - Loss:  2188.5688 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 324 - Loss:  2518.3442 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 325 - Loss:  1598.1975 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 326 - Loss:  1521.8489 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 327 - Loss:  2039.0381 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 328 - Loss:  1694.4985 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 329 - Loss:  1959.8293 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 330 - Loss:  1912.2263 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 331 - Loss:  2423.5208 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 332 - Loss:  2084.3281 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 333 - Loss:  2061.6631 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 334 - Loss:  1601.7740 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 335 - Loss:  1631.9670 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 336 - Loss:  2486.0115 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 337 - Loss:  1590.1355 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 338 - Loss:  1482.9084 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 339 - Loss:  1988.9645 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 340 - Loss:  1453.6384 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 341 - Loss:  2021.1934 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 342 - Loss:  1969.5801 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 343 - Loss:  1749.2629 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 344 - Loss:  2003.4694 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 345 - Loss:  2531.1135 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 346 - Loss:  1957.6841 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 347 - Loss:  1467.8320 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 348 - Loss:  2108.4258 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 349 - Loss:  2320.4360 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 350 - Loss:  1738.5250 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 351 - Loss:  2168.0996 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 352 - Loss:  1798.6006 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 353 - Loss:  1514.4531 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 354 - Loss:  1642.9889 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 355 - Loss:  2722.2896 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 356 - Loss:  2273.1504 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 357 - Loss:  2486.2332 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 358 - Loss:  1508.9850 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 359 - Loss:  1393.6521 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 360 - Loss:  1226.3468 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 361 - Loss:  2355.1865 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 362 - Loss:  2511.1111 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 363 - Loss:  1311.8303 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 364 - Loss:  1540.7329 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 365 - Loss:  1457.4326 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 366 - Loss:  1300.5372 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 367 - Loss:  1866.2999 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 368 - Loss:  2035.4219 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 369 - Loss:  2540.8740 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 370 - Loss:  1698.1416 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 371 - Loss:  1135.6040 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 372 - Loss:  1027.6824 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 373 - Loss:  1880.0017 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 374 - Loss:  1744.8075 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 375 - Loss:  2037.9730 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 376 - Loss:  2061.3679 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 377 - Loss:  1312.2712 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 378 - Loss:  1375.9312 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 379 - Loss:  1458.5813 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 380 - Loss:  1871.0706 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 381 - Loss:  1633.7421 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 382 - Loss:  1302.2145 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 383 - Loss:  2775.1003 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 384 - Loss:  1479.2458 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 385 - Loss:  1308.3064 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 386 - Loss:  1597.4697 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 387 - Loss:  1760.1588 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 388 - Loss:  1416.0615 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 389 - Loss:  1192.7295 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 390 - Loss:  1868.0986 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 391 - Loss:  2298.5659 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 392 - Loss:  1017.7520 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 393 - Loss:  1433.4062 Validation Accuracy: 0.644531\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b18bdb26e9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             valid_acc = sess.run(accuracy, feed_dict={\n\u001b[1;32m     13\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_valid_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros-devel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros-devel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros-devel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ros-devel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ros-devel/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
